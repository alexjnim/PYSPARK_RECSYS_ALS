{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Spark, there is one paritcular recommendation algorithm, Alternating Least Squares (ALS). This algorithm leverages collaborative filtering, which makes recommendations based only on which items users interacted with in the past. That is, it does not require or use any additional features about the users or the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "\n",
    "# select 4 cores to process this\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"ALSExample\")\\\n",
    "        .config(\"spark.executor.cores\", '4')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"data/goodbooks-10k-master/ratings.csv\")\n",
    "ratings.printSchema()\n",
    "ratings.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|    258|     5|\n",
      "|      2|   4081|     4|\n",
      "|      2|    260|     5|\n",
      "+-------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- goodreads_book_id: integer (nullable = true)\n",
      " |-- best_book_id: integer (nullable = true)\n",
      " |-- work_id: integer (nullable = true)\n",
      " |-- books_count: integer (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: double (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- original_publication_year: double (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- work_ratings_count: string (nullable = true)\n",
      " |-- work_text_reviews_count: string (nullable = true)\n",
      " |-- ratings_1: double (nullable = true)\n",
      " |-- ratings_2: integer (nullable = true)\n",
      " |-- ratings_3: integer (nullable = true)\n",
      " |-- ratings_4: integer (nullable = true)\n",
      " |-- ratings_5: integer (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- small_image_url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"data/goodbooks-10k-master/books.csv\")\n",
    "books.printSchema()\n",
    "books.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|book_id|               title|             authors|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|The Hunger Games ...|     Suzanne Collins|\n",
      "|      2|Harry Potter and ...|J.K. Rowling, Mar...|\n",
      "|      3|Twilight (Twiligh...|     Stephenie Meyer|\n",
      "|      4|To Kill a Mocking...|          Harper Lee|\n",
      "|      5|    The Great Gatsby| F. Scott Fitzgerald|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_names = books.select(\"book_id\", \"title\", \"authors\")\n",
    "book_names.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|book_id|count|\n",
      "+-------+-----+\n",
      "|1      |22806|\n",
      "|2      |21850|\n",
      "|4      |19088|\n",
      "|3      |16931|\n",
      "|5      |16604|\n",
      "|17     |16549|\n",
      "|20     |15953|\n",
      "|18     |15855|\n",
      "|23     |15657|\n",
      "|7      |15558|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.groupby(\"book_id\").count().orderBy(\"count\", ascending=False).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if you don't have a indexed book_id, use StringIndexer to change into indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "#split data into training and test set\n",
    "training, test = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "als = ALS()\\\n",
    "  .setMaxIter(5)\\\n",
    "  .setRegParam(0.01)\\\n",
    "  .setUserCol(\"user_id\")\\\n",
    "  .setItemCol(\"book_id\")\\\n",
    "  .setRatingCol(\"rating\")\n",
    "# print(als.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alsModel = als.fit(training)\n",
    "predictions = alsModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS effectively predicted the ratings that a user would give for a particular book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----------+\n",
      "|user_id|book_id|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|   9427|    148|     3| 3.8146927|\n",
      "|  24354|    148|     5| 4.0027723|\n",
      "|  34061|    148|     4| 3.5079865|\n",
      "|  50223|    148|     4|   3.97144|\n",
      "|   1721|    148|     4|  3.206058|\n",
      "|  29827|    148|     4|  4.491929|\n",
      "|  31928|    148|     5|  4.469343|\n",
      "|  35868|    148|     3| 3.3751755|\n",
      "|  40199|    148|     4| 4.4291224|\n",
      "|  10798|    148|     3| 3.7368596|\n",
      "+-------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When covering the cold-start strategy, we can set up an automatic model evaluator when working with ALS. One thing that may not be immediately obvious is that this recommendation problem is really just a kind of regression problem. Since we’re predicting values (ratings) for given users, we want to optimize for reducing the total difference between our users’ ratings and the true values. We can do this using the RegressionEvaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.840571\n"
     ]
    }
   ],
   "source": [
    "# in Python\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator()\\\n",
    "              .setMetricName(\"rmse\")\\\n",
    "              .setLabelCol(\"rating\")\\\n",
    "              .setPredictionCol(\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = %f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error isn't the best! The model can be improvied further by tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Val and Param-Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "parameter_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(als.rank, [1, 5, 10])\n",
    "    .addGrid(als.maxIter, [20])\n",
    "    .addGrid(als.regParam, [0.05, 0.1])\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{Param(parent='ALS_201113d65e36', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
      "  Param(parent='ALS_201113d65e36', name='rank', doc='rank of the factorization'): 1,\n",
      "  Param(parent='ALS_201113d65e36', name='regParam', doc='regularization parameter (>= 0).'): 0.05},\n",
      " {Param(parent='ALS_201113d65e36', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
      "  Param(parent='ALS_201113d65e36', name='rank', doc='rank of the factorization'): 1,\n",
      "  Param(parent='ALS_201113d65e36', name='regParam', doc='regularization parameter (>= 0).'): 0.1},\n",
      " {Param(parent='ALS_201113d65e36', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
      "  Param(parent='ALS_201113d65e36', name='rank', doc='rank of the factorization'): 5,\n",
      "  Param(parent='ALS_201113d65e36', name='regParam', doc='regularization parameter (>= 0).'): 0.05},\n",
      " {Param(parent='ALS_201113d65e36', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
      "  Param(parent='ALS_201113d65e36', name='rank', doc='rank of the factorization'): 5,\n",
      "  Param(parent='ALS_201113d65e36', name='regParam', doc='regularization parameter (>= 0).'): 0.1},\n",
      " {Param(parent='ALS_201113d65e36', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
      "  Param(parent='ALS_201113d65e36', name='rank', doc='rank of the factorization'): 10,\n",
      "  Param(parent='ALS_201113d65e36', name='regParam', doc='regularization parameter (>= 0).'): 0.05},\n",
      " {Param(parent='ALS_201113d65e36', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
      "  Param(parent='ALS_201113d65e36', name='rank', doc='rank of the factorization'): 10,\n",
      "  Param(parent='ALS_201113d65e36', name='regParam', doc='regularization parameter (>= 0).'): 0.1}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidator = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=parameter_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=2\n",
    ")\n",
    "\n",
    "crossval_model = crossvalidator.fit(training)\n",
    "model = crossval_model.bestModel\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.816494\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = %f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some improvement! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now output the top 𝘬 recommendations for each user or book. The model’s recommendForAllUsers method returns a DataFrame of a user_id, an array of recommendations, as well as a rating for each of those books. recommendForAllItems returns a DataFrame of a book_id, as well as the top users for that book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|user_id|              col|\n",
      "+-------+-----------------+\n",
      "|    148|[8616, 5.0621395]|\n",
      "|    148|[7135, 4.8263083]|\n",
      "|    148| [7929, 4.778312]|\n",
      "|    148| [5794, 4.752222]|\n",
      "|    148|[7537, 4.7467303]|\n",
      "+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+------------------+\n",
      "|book_id|               col|\n",
      "+-------+------------------+\n",
      "|   1580|[35641, 6.0571265]|\n",
      "|   1580|[28734, 5.6772246]|\n",
      "|   1580| [43656, 5.641564]|\n",
      "|   1580| [48984, 5.636069]|\n",
      "|   1580|  [48155, 5.49555]|\n",
      "+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# generate top 10 book recs for each user\n",
    "alsModel.recommendForAllUsers(10)\\\n",
    "  .selectExpr(\"user_id\", \"explode(recommendations)\").show(5)\n",
    "\n",
    "# generate top 10 user recommendations for each book \n",
    "alsModel.recommendForAllItems(10)\\\n",
    "  .selectExpr(\"book_id\", \"explode(recommendations)\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select test user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+-------+-------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|user_id|book_id|rating|book_id|title                                                              |authors                                                                         |\n",
      "+-------+-------+------+-------+-------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|78     |1135   |5     |1135   |Dubliners                                                          |James Joyce, Jeri Johnson                                                       |\n",
      "|78     |161    |5     |161    |The Return of the King (The Lord of the Rings, #3)                 |J.R.R. Tolkien                                                                  |\n",
      "|78     |3785   |5     |3785   |On Photography                                                     |Susan Sontag                                                                    |\n",
      "|78     |959    |5     |959    |A Portrait of the Artist as a Young Man                            |James Joyce, Seamus Deane                                                       |\n",
      "|78     |2798   |5     |2798   |I, Claudius (Claudius, #1)                                         |Robert Graves                                                                   |\n",
      "|78     |95     |5     |95     |The Picture of Dorian Gray                                         |Oscar Wilde, Jeffrey Eugenides                                                  |\n",
      "|78     |3508   |5     |3508   |Swann's Way (In Search of Lost Time, #1)                           |Marcel Proust, Simon Vance, Lydia Davis                                         |\n",
      "|78     |934    |5     |934    |Waiting for Godot                                                  |Samuel Beckett                                                                  |\n",
      "|78     |485    |5     |485    |The Brothers Karamazov                                             |Fyodor Dostoyevsky, Richard Pevear, Larissa Volokhonsky                         |\n",
      "|78     |479    |5     |479    |The Prince                                                         |Niccolò Machiavelli, Adolph Caso, Rufus Goodwin, Benjamin Martinez              |\n",
      "|78     |1041   |5     |1041   |The Idiot                                                          |Fyodor Dostoyevsky, Constance Garnett, Alan Myers, Joseph Frank, Anna Brailovsky|\n",
      "|78     |4336   |5     |4336   |Labyrinths:  Selected Stories and Other Writings                   |Jorge Luis Borges, Donald A. Yates, James E. Irby, André Maurois                |\n",
      "|78     |592    |5     |592    |The Master and Margarita                                           |Mikhail Bulgakov, Katherine Tiernan O'Connor, Diana Burgin, Ellendea Proffer    |\n",
      "|78     |1113   |4     |1113   |Thus Spoke Zarathustra                                             |Friedrich Nietzsche, Walter Kaufmann                                            |\n",
      "|78     |2342   |4     |2342   |Beyond Good and Evil                                               |Friedrich Nietzsche, R.J. Hollingdale, Michael Tanner                           |\n",
      "|78     |284    |4     |284    |On the Road                                                        |Jack Kerouac                                                                    |\n",
      "|78     |283    |4     |283    |Good Omens: The Nice and Accurate Prophecies of Agnes Nutter, Witch|Terry Pratchett, Neil Gaiman                                                    |\n",
      "|78     |167    |4     |167    |American Gods (American Gods, #1)                                  |Neil Gaiman                                                                     |\n",
      "|78     |154    |4     |154    |Macbeth                                                            |William Shakespeare                                                             |\n",
      "|78     |4640   |4     |4640   |Cathedral                                                          |Raymond Carver                                                                  |\n",
      "+-------+-------+------+-------+-------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_user_id = 78\n",
    "\n",
    "test_user = ratings.filter(ratings['user_id'] == test_user_id)\n",
    "\n",
    "joinExpression = test_user[\"book_id\"] == book_names['book_id']\n",
    "joinType = 'left'\n",
    "\n",
    "test_user_profile = test_user.join(book_names, joinExpression, joinType)\\\n",
    " .orderBy('rating', ascending = False)\n",
    "\n",
    "test_user_profile.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_books = books.select(\"title\").distinct()\n",
    "\n",
    "\n",
    "books_read = test_user_profile.select(\"title\").distinct()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter for results and join with book names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs = alsModel.recommendForAllUsers(10)\n",
    "\n",
    "test_userRecs = userRecs.filter(userRecs['user_id'] == test_user_id)\\\n",
    "                    .selectExpr(\"user_id\", \"explode(recommendations)\")\n",
    "\n",
    "test_userRecs = test_userRecs.select(\"user_id\", 'col.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+---------+\n",
      "|title                                                                       |rating   |\n",
      "+----------------------------------------------------------------------------+---------+\n",
      "|Damaged: The Heartbreaking True Story of a Forgotten Child                  |5.907332 |\n",
      "|أقوم قيلا                                                                   |5.806222 |\n",
      "|رباعيات خيام                                                                |5.7730765|\n",
      "|Shadow & Claw (The Book of the New Sun #1-2)                                |5.3648663|\n",
      "|The Harbinger: The Ancient Mystery that Holds the Secret of America's Future|5.3429446|\n",
      "|Novecento. Un monologo                                                      |5.236621 |\n",
      "|On the Genealogy of Morals                                                  |5.0507164|\n",
      "|Hopscotch                                                                   |5.0181146|\n",
      "|The Magic Mountain                                                          |4.9790382|\n",
      "|Once (Once, #1)                                                             |4.916561 |\n",
      "+----------------------------------------------------------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinExpression = test_userRecs[\"book_id\"] == book_names['book_id']\n",
    "joinType = \"inner\"\n",
    "\n",
    "recommended_books = test_userRecs.join(book_names, joinExpression, joinType)\n",
    "\n",
    "recommended_books.select(\"title\", \"rating\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can also find top users for a given book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|book_id|               title|             authors|\n",
      "+-------+--------------------+--------------------+\n",
      "|    177|Crime and Punishment|Fyodor Dostoyevsk...|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_book_id = 177\n",
    "\n",
    "book_names.filter(book_names['book_id'] == test_book_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+\n",
      "|book_id|user_id|   rating|\n",
      "+-------+-------+---------+\n",
      "|    177|  35904| 5.975092|\n",
      "|    177|  48743| 5.798015|\n",
      "|    177|  46273| 5.786284|\n",
      "|    177|  45135|5.7776213|\n",
      "|    177|  33840|5.7763076|\n",
      "|    177|  37025| 5.760677|\n",
      "|    177|   3597|5.7047806|\n",
      "|    177|  39883| 5.692147|\n",
      "|    177|  51097|5.6818557|\n",
      "|    177|  24063| 5.635712|\n",
      "+-------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bookRecs = alsModel.recommendForAllItems(10)\\\n",
    "                    .selectExpr(\"book_id\", \"explode(recommendations)\")\n",
    "\n",
    "test_bookRec = bookRecs.filter(bookRecs['book_id'] == test_book_id)\\\n",
    "                        .select(\"book_id\", \"col.*\")\n",
    "\n",
    "test_bookRec.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RankingMetric allows us to compare our recommendations with an actual set of ratings (or preferences) expressed by a given user. RankingMetric does not focus on the value of the rank but rather whether or not our algorithm recommends an already ranked item again to a user. \n",
    "\n",
    "First, we need to collect a set of highly ranked movies for a given user. In our case, we’re going to use a rather low threshold: movies ranked above 2.5. Tuning this value will largely be a business decision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Python\n",
    "from pyspark.mllib.evaluation import RankingMetrics, RegressionMetrics\n",
    "from pyspark.sql.functions import col, expr\n",
    "perUserActual = predictions\\\n",
    "  .where(\"rating > 2.5\")\\\n",
    "  .groupBy(\"user_id\")\\\n",
    "  .agg(expr(\"collect_set(book_id) as books\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a collection of users, along with a truth set of previously ranked movies for each user. Now we will get our top 10 recommendations from our algorithm on a per-user basis. We will then see if the top 10 recommendations show up in our truth set. If we have a well-trained model, it will correctly recommend the movies a user already liked. If it doesn’t, it may not have learned enough about each particular user to successfully reflect their preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "perUserPredictions = predictions\\\n",
    "  .orderBy(col(\"user_id\"), expr(\"prediction DESC\"))\\\n",
    "  .groupBy(\"user_id\")\\\n",
    "  .agg(expr(\"collect_list(book_id) as books\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two DataFrames, one of predictions and another the top-ranked items for a particular user. We can pass them into the RankingMetrics object. This object accepts an RDD of these combinations, as you can see in the following join and RDD conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Python\n",
    "perUserActualvPred = perUserActual.join(perUserPredictions, [\"user_id\"]).rdd\\\n",
    "  .map(lambda row: (row[1], row[2][:15]))\n",
    "ranks = RankingMetrics(perUserActualvPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the metrics from that ranking. For instance, we can see how precise our algorithm is with the mean average precision. We can also get the precision at certain ranking points, for instance, to see where the majority of the positive recommendations fall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6791110445413869"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks.meanAveragePrecision\n",
    "ranks.precisionAt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
