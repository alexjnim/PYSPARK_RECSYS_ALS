{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Spark, there is one paritcular recommendation algorithm, Alternating Least Squares (ALS). This algorithm leverages collaborative filtering, which makes recommendations based only on which items users interacted with in the past. That is, it does not require or use any additional features about the users or the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "\n",
    "# select 4 cores to process this\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"ALSExample\")\\\n",
    "        .config(\"spark.executor.cores\", '4')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"../data/goodbooks-10k-master/ratings.csv\")\n",
    "ratings.printSchema()\n",
    "ratings.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|    258|     5|\n",
      "|      2|   4081|     4|\n",
      "|      2|    260|     5|\n",
      "+-------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- goodreads_book_id: integer (nullable = true)\n",
      " |-- best_book_id: integer (nullable = true)\n",
      " |-- work_id: integer (nullable = true)\n",
      " |-- books_count: integer (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: double (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- original_publication_year: double (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- work_ratings_count: string (nullable = true)\n",
      " |-- work_text_reviews_count: string (nullable = true)\n",
      " |-- ratings_1: double (nullable = true)\n",
      " |-- ratings_2: integer (nullable = true)\n",
      " |-- ratings_3: integer (nullable = true)\n",
      " |-- ratings_4: integer (nullable = true)\n",
      " |-- ratings_5: integer (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- small_image_url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"../data/goodbooks-10k-master/books.csv\")\n",
    "books.printSchema()\n",
    "books.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|book_id|               title|             authors|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|The Hunger Games ...|     Suzanne Collins|\n",
      "|      2|Harry Potter and ...|J.K. Rowling, Mar...|\n",
      "|      3|Twilight (Twiligh...|     Stephenie Meyer|\n",
      "|      4|To Kill a Mocking...|          Harper Lee|\n",
      "|      5|    The Great Gatsby| F. Scott Fitzgerald|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_names = books.select(\"book_id\", \"title\", \"authors\")\n",
    "book_names.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "#split data into training and test set\n",
    "training, test = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "als = ALS()\\\n",
    "  .setMaxIter(5)\\\n",
    "  .setRegParam(0.01)\\\n",
    "  .setUserCol(\"user_id\")\\\n",
    "  .setItemCol(\"book_id\")\\\n",
    "  .setRatingCol(\"rating\")\n",
    "# print(als.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alsModel = als.fit(training)\n",
    "predictions = alsModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When covering the cold-start strategy, we can set up an automatic model evaluator when working with ALS. One thing that may not be immediately obvious is that this recommendation problem is really just a kind of regression problem. Since weâ€™re predicting values (ratings) for given users, we want to optimize for reducing the total difference between our usersâ€™ ratings and the true values. We can do this using the RegressionEvaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.838036\n"
     ]
    }
   ],
   "source": [
    "# in Python\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator()\\\n",
    "  .setMetricName(\"rmse\")\\\n",
    "  .setLabelCol(\"rating\")\\\n",
    "  .setPredictionCol(\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = %f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now output the top ð˜¬ recommendations for each user or book. The modelâ€™s recommendForAllUsers method returns a DataFrame of a user_id, an array of recommendations, as well as a rating for each of those books. recommendForAllItems returns a DataFrame of a book_id, as well as the top users for that book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|user_id|              col|\n",
      "+-------+-----------------+\n",
      "|    148|[9732, 5.3555064]|\n",
      "|    148|   [9134, 5.0563]|\n",
      "|    148| [9842, 4.811599]|\n",
      "|    148|[7305, 4.7891364]|\n",
      "|    148| [8548, 4.756803]|\n",
      "+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+------------------+\n",
      "|book_id|               col|\n",
      "+-------+------------------+\n",
      "|   1580|[40526, 6.0742655]|\n",
      "|   1580| [50817, 5.854666]|\n",
      "|   1580|[46930, 5.7558947]|\n",
      "|   1580| [52237, 5.741843]|\n",
      "|   1580|  [47608, 5.64794]|\n",
      "+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# generate top 10 book recs for each user\n",
    "alsModel.recommendForAllUsers(10)\\\n",
    "  .selectExpr(\"user_id\", \"explode(recommendations)\").show(5)\n",
    "\n",
    "# generate top 10 user recommendations for each book \n",
    "alsModel.recommendForAllItems(10)\\\n",
    "  .selectExpr(\"book_id\", \"explode(recommendations)\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select test user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+-------+-------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|user_id|book_id|rating|book_id|title                                                              |authors                                                                         |\n",
      "+-------+-------+------+-------+-------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|78     |959    |5     |959    |A Portrait of the Artist as a Young Man                            |James Joyce, Seamus Deane                                                       |\n",
      "|78     |485    |5     |485    |The Brothers Karamazov                                             |Fyodor Dostoyevsky, Richard Pevear, Larissa Volokhonsky                         |\n",
      "|78     |3785   |5     |3785   |On Photography                                                     |Susan Sontag                                                                    |\n",
      "|78     |1135   |5     |1135   |Dubliners                                                          |James Joyce, Jeri Johnson                                                       |\n",
      "|78     |161    |5     |161    |The Return of the King (The Lord of the Rings, #3)                 |J.R.R. Tolkien                                                                  |\n",
      "|78     |95     |5     |95     |The Picture of Dorian Gray                                         |Oscar Wilde, Jeffrey Eugenides                                                  |\n",
      "|78     |3508   |5     |3508   |Swann's Way (In Search of Lost Time, #1)                           |Marcel Proust, Simon Vance, Lydia Davis                                         |\n",
      "|78     |2798   |5     |2798   |I, Claudius (Claudius, #1)                                         |Robert Graves                                                                   |\n",
      "|78     |934    |5     |934    |Waiting for Godot                                                  |Samuel Beckett                                                                  |\n",
      "|78     |479    |5     |479    |The Prince                                                         |NiccolÃ² Machiavelli, Adolph Caso, Rufus Goodwin, Benjamin Martinez              |\n",
      "|78     |1041   |5     |1041   |The Idiot                                                          |Fyodor Dostoyevsky, Constance Garnett, Alan Myers, Joseph Frank, Anna Brailovsky|\n",
      "|78     |4336   |5     |4336   |Labyrinths:  Selected Stories and Other Writings                   |Jorge Luis Borges, Donald A. Yates, James E. Irby, AndrÃ© Maurois                |\n",
      "|78     |592    |5     |592    |The Master and Margarita                                           |Mikhail Bulgakov, Katherine Tiernan O'Connor, Diana Burgin, Ellendea Proffer    |\n",
      "|78     |2342   |4     |2342   |Beyond Good and Evil                                               |Friedrich Nietzsche, R.J. Hollingdale, Michael Tanner                           |\n",
      "|78     |167    |4     |167    |American Gods (American Gods, #1)                                  |Neil Gaiman                                                                     |\n",
      "|78     |283    |4     |283    |Good Omens: The Nice and Accurate Prophecies of Agnes Nutter, Witch|Terry Pratchett, Neil Gaiman                                                    |\n",
      "|78     |154    |4     |154    |Macbeth                                                            |William Shakespeare                                                             |\n",
      "|78     |284    |4     |284    |On the Road                                                        |Jack Kerouac                                                                    |\n",
      "|78     |430    |4     |430    |Kafka on the Shore                                                 |Haruki Murakami, Philip Gabriel                                                 |\n",
      "|78     |4640   |4     |4640   |Cathedral                                                          |Raymond Carver                                                                  |\n",
      "+-------+-------+------+-------+-------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_user_id = 78\n",
    "\n",
    "test_user = ratings.filter(ratings['user_id'] == test_user_id)\n",
    "\n",
    "joinExpression = test_user[\"book_id\"] == book_names['book_id']\n",
    "joinType = 'left'\n",
    "\n",
    "test_user_profile = test_user.join(book_names, joinExpression, joinType)\\\n",
    " .orderBy('rating', ascending = False)\n",
    "\n",
    "test_user_profile.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9964\n",
      "\n",
      "\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "unique_books = books.select(\"title\").distinct()\n",
    "\n",
    "\n",
    "books_read = test_user_profile.select(\"title\").distinct()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter for results and join with book names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs = alsModel.recommendForAllUsers(10)\n",
    "\n",
    "test_userRecs = userRecs.filter(userRecs['user_id'] == test_user_id)\\\n",
    "                    .selectExpr(\"user_id\", \"explode(recommendations)\")\n",
    "\n",
    "test_userRecs = test_userRecs.select(\"user_id\", 'col.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------+---------+\n",
      "|title                                                                                       |rating   |\n",
      "+--------------------------------------------------------------------------------------------+---------+\n",
      "|In the Penal Colony                                                                         |5.9798265|\n",
      "|Gravity's Rainbow                                                                           |5.6863956|\n",
      "|Misquoting Jesus: The Story Behind Who Changed the Bible and Why                            |5.4828916|\n",
      "|The Work of Art in the Age of Its Technological Reproducibility, and Other Writings on Media|5.3400025|\n",
      "|Under the Volcano                                                                           |5.323349 |\n",
      "|Austerlitz                                                                                  |5.200412 |\n",
      "|Baltasar and Blimunda                                                                       |5.129198 |\n",
      "|Hopscotch                                                                                   |5.107964 |\n",
      "|The Book on the Taboo Against Knowing Who You Are                                           |5.1010637|\n",
      "|Novecento. Un monologo                                                                      |5.0863705|\n",
      "+--------------------------------------------------------------------------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinExpression = test_userRecs[\"book_id\"] == book_names['book_id']\n",
    "joinType = \"inner\"\n",
    "\n",
    "recommended_books = test_userRecs.join(book_names, joinExpression, joinType)\n",
    "\n",
    "recommended_books.select(\"title\", \"rating\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can also find top users for a given book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|book_id|               title|             authors|\n",
      "+-------+--------------------+--------------------+\n",
      "|    177|Crime and Punishment|Fyodor Dostoyevsk...|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_book_id = 177\n",
    "\n",
    "book_names.filter(book_names['book_id'] == test_book_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+\n",
      "|book_id|user_id|   rating|\n",
      "+-------+-------+---------+\n",
      "|    177|  38367| 6.388581|\n",
      "|    177|  40948|6.2325187|\n",
      "|    177|  43800|6.1170244|\n",
      "|    177|  15344|5.8767686|\n",
      "|    177|  14215|5.7751093|\n",
      "|    177|  40753| 5.655826|\n",
      "|    177|  31196|5.6470795|\n",
      "|    177|  28982| 5.641826|\n",
      "|    177|  23621|5.5977125|\n",
      "|    177|  35183| 5.591388|\n",
      "+-------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bookRecs = alsModel.recommendForAllItems(10)\\\n",
    "                    .selectExpr(\"book_id\", \"explode(recommendations)\")\n",
    "\n",
    "test_bookRec = bookRecs.filter(bookRecs['book_id'] == test_book_id)\\\n",
    "                        .select(\"book_id\", \"col.*\")\n",
    "\n",
    "test_bookRec.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RankingMetric allows us to compare our recommendations with an actual set of ratings (or preferences) expressed by a given user. RankingMetric does not focus on the value of the rank but rather whether or not our algorithm recommends an already ranked item again to a user. \n",
    "\n",
    "First, we need to collect a set of highly ranked movies for a given user. In our case, weâ€™re going to use a rather low threshold: movies ranked above 2.5. Tuning this value will largely be a business decision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Python\n",
    "from pyspark.mllib.evaluation import RankingMetrics, RegressionMetrics\n",
    "from pyspark.sql.functions import col, expr\n",
    "perUserActual = predictions\\\n",
    "  .where(\"rating > 2.5\")\\\n",
    "  .groupBy(\"user_id\")\\\n",
    "  .agg(expr(\"collect_set(book_id) as books\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a collection of users, along with a truth set of previously ranked movies for each user. Now we will get our top 10 recommendations from our algorithm on a per-user basis. We will then see if the top 10 recommendations show up in our truth set. If we have a well-trained model, it will correctly recommend the movies a user already liked. If it doesnâ€™t, it may not have learned enough about each particular user to successfully reflect their preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "perUserPredictions = predictions\\\n",
    "  .orderBy(col(\"user_id\"), expr(\"prediction DESC\"))\\\n",
    "  .groupBy(\"user_id\")\\\n",
    "  .agg(expr(\"collect_list(book_id) as books\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two DataFrames, one of predictions and another the top-ranked items for a particular user. We can pass them into the RankingMetrics object. This object accepts an RDD of these combinations, as you can see in the following join and RDD conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Python\n",
    "perUserActualvPred = perUserActual.join(perUserPredictions, [\"user_id\"]).rdd\\\n",
    "  .map(lambda row: (row[1], row[2][:15]))\n",
    "ranks = RankingMetrics(perUserActualvPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the metrics from that ranking. For instance, we can see how precise our algorithm is with the mean average precision. We can also get the precision at certain ranking points, for instance, to see where the majority of the positive recommendations fall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6791110445413869"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks.meanAveragePrecision\n",
    "ranks.precisionAt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
