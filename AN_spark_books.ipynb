{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Spark, there is one paritcular recommendation algorithm, Alternating Least Squares (ALS). This algorithm leverages collaborative filtering, which makes recommendations based only on which items users interacted with in the past. That is, it does not require or use any additional features about the users or the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "\n",
    "# select 4 cores to process this\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"ALSExample\")\\\n",
    "        .config(\"spark.executor.cores\", '4')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"../data/goodbooks-10k-master/ratings.csv\")\n",
    "ratings.printSchema()\n",
    "ratings.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|    258|     5|\n",
      "|      2|   4081|     4|\n",
      "|      2|    260|     5|\n",
      "+-------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- goodreads_book_id: integer (nullable = true)\n",
      " |-- best_book_id: integer (nullable = true)\n",
      " |-- work_id: integer (nullable = true)\n",
      " |-- books_count: integer (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: double (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- original_publication_year: double (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- work_ratings_count: string (nullable = true)\n",
      " |-- work_text_reviews_count: string (nullable = true)\n",
      " |-- ratings_1: double (nullable = true)\n",
      " |-- ratings_2: integer (nullable = true)\n",
      " |-- ratings_3: integer (nullable = true)\n",
      " |-- ratings_4: integer (nullable = true)\n",
      " |-- ratings_5: integer (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- small_image_url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"../data/goodbooks-10k-master/books.csv\")\n",
    "books.printSchema()\n",
    "books.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|book_id|               title|             authors|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|The Hunger Games ...|     Suzanne Collins|\n",
      "|      2|Harry Potter and ...|J.K. Rowling, Mar...|\n",
      "|      3|Twilight (Twiligh...|     Stephenie Meyer|\n",
      "|      4|To Kill a Mocking...|          Harper Lee|\n",
      "|      5|    The Great Gatsby| F. Scott Fitzgerald|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_names = books.select(\"book_id\", \"title\", \"authors\")\n",
    "book_names.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "#split data into training and test set\n",
    "training, test = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "als = ALS()\\\n",
    "  .setMaxIter(5)\\\n",
    "  .setRegParam(0.01)\\\n",
    "  .setUserCol(\"user_id\")\\\n",
    "  .setItemCol(\"book_id\")\\\n",
    "  .setRatingCol(\"rating\")\n",
    "# print(als.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "alsModel = als.fit(training)\n",
    "predictions = alsModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When covering the cold-start strategy, we can set up an automatic model evaluator when working with ALS. One thing that may not be immediately obvious is that this recommendation problem is really just a kind of regression problem. Since weâ€™re predicting values (ratings) for given users, we want to optimize for reducing the total difference between our usersâ€™ ratings and the true values. We can do this using the RegressionEvaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.841255\n"
     ]
    }
   ],
   "source": [
    "# in Python\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator()\\\n",
    "  .setMetricName(\"rmse\")\\\n",
    "  .setLabelCol(\"rating\")\\\n",
    "  .setPredictionCol(\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = %f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now output the top ð˜¬ recommendations for each user or book. The modelâ€™s recommendForAllUsers method returns a DataFrame of a user_id, an array of recommendations, as well as a rating for each of those books. recommendForAllItems returns a DataFrame of a book_id, as well as the top users for that book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|user_id|              col|\n",
      "+-------+-----------------+\n",
      "|    148| [8326, 5.287354]|\n",
      "|    148|[8498, 5.2569065]|\n",
      "|    148|[8703, 5.2383165]|\n",
      "|    148|[9576, 5.2006955]|\n",
      "|    148|[8271, 5.1758304]|\n",
      "+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+------------------+\n",
      "|book_id|               col|\n",
      "+-------+------------------+\n",
      "|   1580| [40753, 5.755218]|\n",
      "|   1580|[51314, 5.5977416]|\n",
      "|   1580|[50817, 5.5185285]|\n",
      "|   1580| [24329, 5.516051]|\n",
      "|   1580|[43544, 5.4652486]|\n",
      "+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# generate top 10 book recs for each user\n",
    "alsModel.recommendForAllUsers(10)\\\n",
    "  .selectExpr(\"user_id\", \"explode(recommendations)\").show(5)\n",
    "\n",
    "# generate top 10 user recommendations for each book \n",
    "alsModel.recommendForAllItems(10)\\\n",
    "  .selectExpr(\"book_id\", \"explode(recommendations)\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select test user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+-------+----------------------------------------+\n",
      "|user_id|book_id|rating|book_id|title                                   |\n",
      "+-------+-------+------+-------+----------------------------------------+\n",
      "|8      |977    |5     |977    |Inferno (The Divine Comedy #1)          |\n",
      "|8      |8312   |5     |8312   |Miracles                                |\n",
      "|8      |769    |5     |769    |The Complete Sherlock Holmes            |\n",
      "|8      |5425   |5     |5425   |Darkness at Noon                        |\n",
      "|8      |80     |5     |80     |The Little Prince                       |\n",
      "|8      |485    |5     |485    |The Brothers Karamazov                  |\n",
      "|8      |718    |5     |718    |The Sound and the Fury                  |\n",
      "|8      |493    |5     |493    |Mere Christianity                       |\n",
      "|8      |362    |5     |362    |The Screwtape Letters                   |\n",
      "|8      |9114   |5     |9114   |The Complete Tales and Poems            |\n",
      "|8      |177    |5     |177    |Crime and Punishment                    |\n",
      "|8      |778    |5     |778    |The Hunchback of Notre-Dame             |\n",
      "|8      |529    |5     |529    |Gulliver's Travels                      |\n",
      "|8      |55     |5     |55     |Brave New World                         |\n",
      "|8      |2584   |5     |2584   |Down and Out in Paris and London        |\n",
      "|8      |1214   |5     |1214   |Ulysses                                 |\n",
      "|8      |3020   |5     |3020   |The Metamorphosis and Other Stories     |\n",
      "|8      |14     |5     |14     |Animal Farm                             |\n",
      "|8      |2732   |5     |2732   |Utopia                                  |\n",
      "|8      |4622   |5     |4622   |Franz Kafka's The Castle (Dramatization)|\n",
      "+-------+-------+------+-------+----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_user_id = 8\n",
    "\n",
    "test_user = ratings.filter(ratings['user_id'] == test_user_id)\n",
    "joinExpression = test_user[\"book_id\"] == book_names['book_id']\n",
    "test_user.join(book_names, joinExpression, joinType)\\\n",
    " .orderBy('rating', ascending = False).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter for results and join with book names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs = alsModel.recommendForAllUsers(10)\n",
    "\n",
    "test_userRecs = userRecs.filter(userRecs['user_id'] == test_user_id)\\\n",
    "                    .selectExpr(\"user_id\", \"explode(recommendations)\")\n",
    "\n",
    "test_userRecs = test_userRecs.select(\"user_id\", 'col.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+-------+--------------------------------------------------------------------+------------------------------------+\n",
      "|user_id|book_id|rating   |book_id|title                                                               |authors                             |\n",
      "+-------+-------+---------+-------+--------------------------------------------------------------------+------------------------------------+\n",
      "|8      |7548   |6.3333125|7548   |Systematic Theology: An Introduction to Biblical Doctrine           |Wayne A. Grudem                     |\n",
      "|8      |8390   |6.038451 |8390   |Philosophical Investigations                                        |Ludwig Wittgenstein, G.E.M. Anscombe|\n",
      "|8      |9549   |5.9829793|9549   |Gargantua and Pantagruel                                            |FranÃ§ois Rabelais, M.A. Screech     |\n",
      "|8      |8011   |5.794862 |8011   |An Enquiry Concerning Human Understanding                           |David Hume                          |\n",
      "|8      |6272   |5.770591 |6272   |Being and Time                                                      |Martin Heidegger                    |\n",
      "|8      |6375   |5.73251  |6375   |The First Man in Rome (Masters of Rome, #1)                         |Colleen McCullough                  |\n",
      "|8      |7517   |5.706341 |7517   |Six Easy Pieces: Essentials of Physics By Its Most Brilliant Teacher|Richard Feynman                     |\n",
      "|8      |9923   |5.678812 |9923   |The Green Mile, Part 5: Night Journey                               |Stephen King                        |\n",
      "|8      |9918   |5.646758 |9918   |Trouble in Mudbug (Ghost-in-Law, #1)                                |Jana Deleon                         |\n",
      "|8      |7392   |5.637045 |7392   |Fear and Trembling                                                  |SÃ¸ren Kierkegaard, Alastair Hannay  |\n",
      "+-------+-------+---------+-------+--------------------------------------------------------------------+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinExpression = test_userRecs[\"book_id\"] == book_names['book_id']\n",
    "joinType = \"inner\"\n",
    "test_userRecs.join(book_names, joinExpression, joinType).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can also find top users for a given book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|book_id|               title|             authors|\n",
      "+-------+--------------------+--------------------+\n",
      "|    177|Crime and Punishment|Fyodor Dostoyevsk...|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_book_id = 177\n",
    "\n",
    "book_names.filter(book_names['book_id'] == test_book_id).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+\n",
      "|book_id|user_id|   rating|\n",
      "+-------+-------+---------+\n",
      "|    177|  38367| 6.388581|\n",
      "|    177|  40948|6.2325187|\n",
      "|    177|  43800|6.1170244|\n",
      "|    177|  15344|5.8767686|\n",
      "|    177|  14215|5.7751093|\n",
      "|    177|  40753| 5.655826|\n",
      "|    177|  31196|5.6470795|\n",
      "|    177|  28982| 5.641826|\n",
      "|    177|  23621|5.5977125|\n",
      "|    177|  35183| 5.591388|\n",
      "+-------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bookRecs = alsModel.recommendForAllItems(10)\\\n",
    "                    .selectExpr(\"book_id\", \"explode(recommendations)\")\n",
    "\n",
    "test_bookRec = bookRecs.filter(bookRecs['book_id'] == test_book_id)\\\n",
    "                        .select(\"book_id\", \"col.*\")\n",
    "\n",
    "test_bookRec.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RankingMetric allows us to compare our recommendations with an actual set of ratings (or preferences) expressed by a given user. RankingMetric does not focus on the value of the rank but rather whether or not our algorithm recommends an already ranked item again to a user. \n",
    "\n",
    "First, we need to collect a set of highly ranked movies for a given user. In our case, weâ€™re going to use a rather low threshold: movies ranked above 2.5. Tuning this value will largely be a business decision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Python\n",
    "from pyspark.mllib.evaluation import RankingMetrics, RegressionMetrics\n",
    "from pyspark.sql.functions import col, expr\n",
    "perUserActual = predictions\\\n",
    "  .where(\"rating > 2.5\")\\\n",
    "  .groupBy(\"user_id\")\\\n",
    "  .agg(expr(\"collect_set(book_id) as books\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a collection of users, along with a truth set of previously ranked movies for each user. Now we will get our top 10 recommendations from our algorithm on a per-user basis. We will then see if the top 10 recommendations show up in our truth set. If we have a well-trained model, it will correctly recommend the movies a user already liked. If it doesnâ€™t, it may not have learned enough about each particular user to successfully reflect their preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "perUserPredictions = predictions\\\n",
    "  .orderBy(col(\"user_id\"), expr(\"prediction DESC\"))\\\n",
    "  .groupBy(\"user_id\")\\\n",
    "  .agg(expr(\"collect_list(book_id) as books\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two DataFrames, one of predictions and another the top-ranked items for a particular user. We can pass them into the RankingMetrics object. This object accepts an RDD of these combinations, as you can see in the following join and RDD conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Python\n",
    "perUserActualvPred = perUserActual.join(perUserPredictions, [\"user_id\"]).rdd\\\n",
    "  .map(lambda row: (row[1], row[2][:15]))\n",
    "ranks = RankingMetrics(perUserActualvPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the metrics from that ranking. For instance, we can see how precise our algorithm is with the mean average precision. We can also get the precision at certain ranking points, for instance, to see where the majority of the positive recommendations fall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6791110445413869"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks.meanAveragePrecision\n",
    "ranks.precisionAt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
